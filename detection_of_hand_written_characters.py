# -*- coding: utf-8 -*-
"""Detection of hand written characters

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ublo98u7DzSkGe3Q9WaJHP5a7siSv9oz

Data Loading and Preprocessing
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d sachinpatel21/az-handwritten-alphabets-in-csv-format

import zipfile
zip_ref = zipfile.ZipFile('/content/az-handwritten-alphabets-in-csv-format.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()
#/content/az-handwritten-alphabets-in-csv-format.zip

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import cv2

# Load data
data = pd.read_csv('/content/A_Z Handwritten Data.csv', header=None).astype('float32')
print(data.head())

# Split data into features (x) and labels (y)
x = data.drop([0], axis=1)
y = data[0]

# Split into train and test sets
train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2)

# Reshape the data for model input
train_x = np.reshape(train_x.values, (train_x.shape[0], 28, 28))
test_x = np.reshape(test_x.values, (test_x.shape[0], 28, 28))

# Print data shapes
print("Train data shape: ", train_x.shape)
print("Test data shape: ", test_x.shape)

# Dictionary for word labels
word_dict = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L',
             12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W',
             23: 'X', 24: 'Y', 25: 'Z'}

"""Data Transformation"""

# Reshape the train and test data for CNN input
train_X = train_x.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)
test_X = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)
print("New shape of train data: ", train_X.shape)
print("New shape of test data: ", test_X.shape)

# One-hot encoding of labels
train_Y = to_categorical(train_y, num_classes=26)
test_Y = to_categorical(test_y, num_classes=26)

"""Model Creation"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping

# Build the CNN model
model = Sequential()
model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPool2D(pool_size=(2, 2), strides=2))
model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(MaxPool2D(pool_size=(2, 2), strides=2))
model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid'))
model.add(MaxPool2D(pool_size=(2, 2), strides=2))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(26, activation='softmax'))

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

"""Model Training"""

# Callbacks for learning rate reduction and early stopping
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)
early_stop = EarlyStopping(monitor='val_loss', patience=1)

# Train the model
history = model.fit(train_X, train_Y, epochs=5, validation_data=(test_X, test_Y), callbacks=[reduce_lr, early_stop])

"""Model Evaluation"""

# Evaluate the model
loss, accuracy = model.evaluate(test_X, test_Y, verbose=0)
print("Loss:", loss)
print("Accuracy:", accuracy)

"""Visualization"""

import matplotlib.pyplot as plt

# Plot predictions
fig, axes = plt.subplots(3, 3, figsize=(8, 9))
axes = axes.flatten()
for i, ax in enumerate(axes):
    img = np.reshape(test_X[i], (28, 28))
    ax.imshow(img, cmap='Greys')
    pred = word_dict[np.argmax(test_Y[i])]
    ax.set_title("Prediction: " + pred)
plt.show()

"""Model Saving and Image Prediction"""

from keras.models import load_model
model=load_model('model.h5')
words={0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z',
}
from google.colab.patches import cv2_imshow
import cv2
import numpy as np

# Verify the file path and ensure the image exists
image_path = '/content/y.jpg'
img = cv2.imread(image_path)

# Check if the image was loaded successfully
if img is None:
  print(f"Error: Could not load image from {image_path}. Please check the file path and ensure the image exists.")
else:
  img_copy = img.copy()
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  img = cv2.resize(img, (400, 440))
  img_copy = cv2.GaussianBlur(img_copy, (7, 7), 0)
  img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)
  _, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)
  img_final = cv2.resize(img_thresh, (28, 28))
  img_final = np.reshape(img_final, (1, 28, 28, 1))

  # Assuming word_dict is defined elsewhere in your code
  img_pred = word_dict[np.argmax(model.predict(img_final))]
  window_name = 'image'
  cv2.putText(img, "Prediction: " + img_pred, (20, 40), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.3, color=(0, 0, 0))

  cv2_imshow(img)
  cv2.waitKey(0)
  cv2.destroyAllWindows()

from google.colab import drive
drive.mount('/content/drive')